{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=\"The best Monty Python sketch is the one about the dead parrot, I laughed so hard.\"\n",
    "B=\"I laugh when I think about Python's Ministry of Silly Walks sketch, it is funny, funny, funny, the best!\"\n",
    "C=\"Chocolate is the best ice cream dessert topping, with a great taste.\"\n",
    "D=\"The Lumberjack Song is the funniest Monty Python bit: I can't think of it without laughing.\"\n",
    "E=\"I would rather put strawberries on my ice cream for dessert, they have the best taste.\"\n",
    "F=\"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\"\n",
    "sentences= [A, B, C, D, E, F]\n",
    "sent_list=[]\n",
    "for x in sentences:\n",
    "    sent_list.append(x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'when',\n",
       " 'silly',\n",
       " 'bit:',\n",
       " 'accompaniment',\n",
       " 'cream.',\n",
       " 'the',\n",
       " 'strawberries',\n",
       " 'about',\n",
       " 'laugh',\n",
       " 'laughing.',\n",
       " 'best',\n",
       " 'have',\n",
       " 'tasty',\n",
       " 'parrot,',\n",
       " 'ice',\n",
       " 'it',\n",
       " 'funniest',\n",
       " 'funny,',\n",
       " 'topping,',\n",
       " 'taste',\n",
       " 'one',\n",
       " 'dead',\n",
       " 'mint',\n",
       " 'sketch',\n",
       " 'great',\n",
       " 'of',\n",
       " 'song',\n",
       " 'put',\n",
       " 'to',\n",
       " 'without',\n",
       " \"can't\",\n",
       " 'lumberjack',\n",
       " 'on',\n",
       " \"python's\",\n",
       " 'would',\n",
       " 'is',\n",
       " 'so',\n",
       " 'fantastic',\n",
       " 'rather',\n",
       " 'my',\n",
       " 'with',\n",
       " 'they',\n",
       " 'taste.',\n",
       " 'dessert,',\n",
       " 'walks',\n",
       " 'dessert',\n",
       " 'python',\n",
       " 'monty',\n",
       " 'i',\n",
       " 'laughed',\n",
       " 'chocolate',\n",
       " 'best!',\n",
       " 'caramel',\n",
       " 'the',\n",
       " 'ministry',\n",
       " 'sketch,',\n",
       " 'think',\n",
       " 'hard.',\n",
       " 'for',\n",
       " 'cream']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.lower() for x in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>when</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>monty</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bit:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accompaniment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cream.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>strawberries</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>about</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laugh</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laughing.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>have</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tasty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>parrot,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>song</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funniest</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funny,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>topping,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taste</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>python</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dead</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mint</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sketch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>great</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>put</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>without</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>can't</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>would</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>silly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cream</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fantastic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walks</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rather</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>my</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>with</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>they</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taste.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lumberjack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dessert,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ministry</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dessert</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laughed</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>caramel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sketch,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>think</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hard.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>python's</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>for</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chocolate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4  5\n",
       "a              0  0  1  0  0  1\n",
       "when           0  1  0  0  0  0\n",
       "monty          1  0  0  1  0  0\n",
       "bit:           0  0  0  0  0  0\n",
       "accompaniment  0  0  0  0  0  1\n",
       "cream.         0  0  0  0  0  0\n",
       "the            3  1  1  2  1  1\n",
       "strawberries   0  0  0  0  1  0\n",
       "about          1  1  0  0  0  0\n",
       "laugh          0  1  0  0  0  0\n",
       "laughing.      0  0  0  0  0  0\n",
       "best           1  1  1  0  1  0\n",
       "have           0  0  0  0  1  0\n",
       "tasty          0  0  0  0  0  1\n",
       "parrot,        0  0  0  0  0  0\n",
       "ice            0  0  1  0  1  1\n",
       "it             0  1  0  1  0  0\n",
       "song           0  0  0  1  0  0\n",
       "funniest       0  0  0  1  0  0\n",
       "funny,         0  0  0  0  0  0\n",
       "topping,       0  0  0  0  0  0\n",
       "taste          0  0  1  0  1  1\n",
       "python         1  1  0  1  0  0\n",
       "one            1  0  0  0  0  0\n",
       "dead           1  0  0  0  0  0\n",
       "mint           0  0  0  0  0  1\n",
       "sketch         1  1  0  0  0  0\n",
       "great          0  0  1  0  0  0\n",
       "of             0  1  0  1  0  1\n",
       "put            0  0  0  0  1  0\n",
       "to             0  0  0  0  0  1\n",
       "without        0  0  0  1  0  0\n",
       "can't          0  0  0  0  0  0\n",
       "would          0  0  0  0  1  0\n",
       "silly          0  1  0  0  0  0\n",
       "is             1  1  1  1  0  1\n",
       "so             1  0  0  0  0  0\n",
       "cream          0  0  1  0  1  1\n",
       "fantastic      0  0  0  0  0  1\n",
       "walks          0  1  0  0  0  0\n",
       "rather         0  0  0  0  1  0\n",
       "my             0  0  0  0  1  0\n",
       "with           0  0  1  0  0  0\n",
       "they           0  0  0  0  1  0\n",
       "i              1  2  0  1  1  0\n",
       "taste.         0  0  0  0  0  0\n",
       "lumberjack     0  0  0  1  0  0\n",
       "dessert,       0  0  0  0  0  0\n",
       "ministry       0  1  0  0  0  0\n",
       "dessert        0  0  1  0  1  0\n",
       "laughed        1  0  0  0  0  0\n",
       "best!          0  0  0  0  0  0\n",
       "caramel        0  0  0  0  0  1\n",
       "sketch,        0  0  0  0  0  0\n",
       "think          0  1  0  1  0  0\n",
       "hard.          0  0  0  0  0  0\n",
       "python's       0  0  0  0  0  0\n",
       "for            0  0  0  0  1  0\n",
       "chocolate      0  0  1  0  0  0\n",
       "on             0  0  0  0  1  0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [A, B, C, D, E, F]\n",
    "ser= pd.Series(corpus).apply(lambda x: x.split())\n",
    "vocab= list(set().union(*ser))\n",
    "vocab= list(set([x.lower() for x in vocab]))\n",
    "df = pd.DataFrame(data=corpus, columns=['sentences'])\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab, min_df=0,\n",
    "                             token_pattern=r\"(?u)\\b\\w+\\b\")\n",
    "X = vectorizer.fit_transform(df['sentences'].values)\n",
    "td_matrix = pd.DataFrame(data=X.toarray(), columns=vectorizer.get_feature_names()).T\n",
    "td_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df</th>\n",
       "      <th>cf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>when</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>monty</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>bit:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>accompaniment</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cream.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>strawberries</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>about</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laugh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laughing.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>have</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tasty</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>parrot,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ice</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>song</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funniest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funny,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>topping,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taste</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>python</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dead</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mint</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sketch</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>of</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>put</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>without</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>can't</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>would</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>silly</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.263034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>so</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cream</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>fantastic</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>walks</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rather</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>my</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>they</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taste.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lumberjack</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dessert,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ministry</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dessert</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laughed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>caramel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sketch,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>think</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hard.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>python's</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>for</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>chocolate</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.584963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               df  cf       idf\n",
       "a               2   2  1.584963\n",
       "when            1   1  2.584963\n",
       "monty           2   2  1.584963\n",
       "bit:            0   0       inf\n",
       "accompaniment   1   1  2.584963\n",
       "cream.          0   0       inf\n",
       "the             6   9  0.000000\n",
       "strawberries    1   1  2.584963\n",
       "about           2   2  1.584963\n",
       "laugh           1   1  2.584963\n",
       "laughing.       0   0       inf\n",
       "best            4   4  0.584963\n",
       "have            1   1  2.584963\n",
       "tasty           1   1  2.584963\n",
       "parrot,         0   0       inf\n",
       "ice             3   3  1.000000\n",
       "it              2   2  1.584963\n",
       "song            1   1  2.584963\n",
       "funniest        1   1  2.584963\n",
       "funny,          0   0       inf\n",
       "topping,        0   0       inf\n",
       "taste           3   3  1.000000\n",
       "python          3   3  1.000000\n",
       "one             1   1  2.584963\n",
       "dead            1   1  2.584963\n",
       "mint            1   1  2.584963\n",
       "sketch          2   2  1.584963\n",
       "great           1   1  2.584963\n",
       "of              3   3  1.000000\n",
       "put             1   1  2.584963\n",
       "to              1   1  2.584963\n",
       "without         1   1  2.584963\n",
       "can't           0   0       inf\n",
       "would           1   1  2.584963\n",
       "silly           1   1  2.584963\n",
       "is              5   5  0.263034\n",
       "so              1   1  2.584963\n",
       "cream           3   3  1.000000\n",
       "fantastic       1   1  2.584963\n",
       "walks           1   1  2.584963\n",
       "rather          1   1  2.584963\n",
       "my              1   1  2.584963\n",
       "with            1   1  2.584963\n",
       "they            1   1  2.584963\n",
       "i               4   5  0.584963\n",
       "taste.          0   0       inf\n",
       "lumberjack      1   1  2.584963\n",
       "dessert,        0   0       inf\n",
       "ministry        1   1  2.584963\n",
       "dessert         2   2  1.584963\n",
       "laughed         1   1  2.584963\n",
       "best!           0   0       inf\n",
       "caramel         1   1  2.584963\n",
       "sketch,         0   0       inf\n",
       "think           2   2  1.584963\n",
       "hard.           0   0       inf\n",
       "python's        0   0       inf\n",
       "for             1   1  2.584963\n",
       "chocolate       1   1  2.584963\n",
       "on              1   1  2.584963"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dfcf=pd.DataFrame(index=td_matrix.index)\n",
    "dfcf['df']=0\n",
    "dfcf['df']=td_matrix.apply(np.count_nonzero, axis=1)\n",
    "dfcf['cf']=td_matrix.apply(np.sum, axis=1)\n",
    "dfcf['idf']= np.log2(6/dfcf.df)\n",
    "dfcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcgow\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>monty</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sketch</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>1.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>python</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laugh</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4    5\n",
       "monty   1.584963  0.000000  0.000000  1.584963  0.000000  0.0\n",
       "sketch  1.584963  1.584963  0.000000  0.000000  0.000000  0.0\n",
       "python  1.000000  1.000000  0.000000  1.000000  0.000000  0.0\n",
       "laugh   0.000000  2.584963  0.000000  0.000000  0.000000  0.0\n",
       "funny        NaN       NaN       NaN       NaN       NaN  NaN\n",
       "best    0.584963  0.584963  0.584963  0.000000  0.584963  0.0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_matrix.apply(lambda x: x*dfcf.idf, axis=0).loc[['monty', 'sketch', 'python', 'laugh', 'funny', 'best']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input=['The', 'best', 'Monty', 'Python', 'sketch', 'is', 'the',\n",
       "                       'one', 'about', 'the', 'dead', 'parrot,', 'I', 'laughed',\n",
       "                       'so', 'hard.', 'I', 'laugh', 'when', 'I', 'think',\n",
       "                       'about', \"Python's\", 'Ministry', 'of', 'Silly', 'Walks',\n",
       "                       'sketch,', 'it', 'is', ...],\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "tf= TfidfVectorizer(all_sents)\n",
    "tf_matrix=tf.fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the text the lazy way.\n",
    "gatsby=\"In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since. \\\"Whenever you feel like criticizing any one,\\\" he told me, \\\"just remember that all the people in this world haven't had the advantages that you've had.\\\" He didn't say any more but we've always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence I'm inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men. Most of the confidences were unsought--frequently I have feigned sleep, preoccupation, or a hostile levity when I realized by some unmistakable sign that an intimate revelation was quivering on the horizon--for the intimate revelations of young men or at least the terms in which they express them are usually plagiaristic and marred by obvious suppressions. Reserving judgments is a matter of infinite hope. I am still a little afraid of missing something if I forget that, as my father snobbishly suggested, and I snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth. And, after boasting this way of my tolerance, I come to the admission that it has a limit. Conduct may be founded on the hard rock or the wet marshes but after a certain point I don't care what it's founded on. When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart. Only Gatsby, the man who gives his name to this book, was exempt from my reaction--Gatsby who represented everything for which I have an unaffected scorn. If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away. This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \\\"creative temperament\\\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again. No--Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men.\"\n",
    "\n",
    "# We want to use the standard english-language parser.\n",
    "parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Parsing Gatsby.\n",
    "gatsby = parser(gatsby)\n",
    "\n",
    "# Dividing the text into sentences and storing them as a list of strings.\n",
    "sentences=[]\n",
    "for span in gatsby.sents:\n",
    "    # go from the start to the end of each span, returning each token in the sentence\n",
    "    # combine each token using join()\n",
    "    sent = ''.join(gatsby[i].string for i in range(span.start, span.end)).strip()\n",
    "    sentences.append(sent)\n",
    "\n",
    "# Creating the tf-idf matrix.\n",
    "counter = TfidfVectorizer(lowercase=False, \n",
    "                          stop_words=None,\n",
    "                          ngram_range=(1, 1), \n",
    "                          analyzer=u'word', \n",
    "                          max_df=.5, \n",
    "                          min_df=1,\n",
    "                          max_features=None, \n",
    "                          vocabulary=None, \n",
    "                          binary=False)\n",
    "#Applying the vectorizer\n",
    "data_counts=counter.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.07458830063813306, 'This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \"creative temperament\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again.')\n"
     ]
    }
   ],
   "source": [
    "# Calculating similarity\n",
    "similarity = data_counts * data_counts.T\n",
    "\n",
    "# Identifying the sentence with the highest rank.\n",
    "nx_graph = nx.from_scipy_sparse_matrix(similarity)\n",
    "ranks=nx.pagerank(nx_graph, alpha=.85, tol=.00000001)\n",
    "\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(sentences)),\n",
    "                reverse=True)\n",
    "print(ranked[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words and punctuation, then getting a list of all unique words in the text\n",
    "gatsby_filt = [word for word in gatsby if word.is_stop==False and (word.pos_=='NOUN' or word.pos_=='ADJ')]\n",
    "words=set(gatsby_filt)\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency=pd.DataFrame(columns=words,index=words,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(gatsby):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in gatsby_filt]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "        end=max(0,len(gatsby)-(len(gatsby)-(i+5)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=gatsby[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in gatsby_filt for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency.loc[word,neighbors]=adjacency.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcgow\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.013842411165984558, hope), (0.012538179113556777, promises), (0.012538179113556777, exempt), (0.012455008769377494, glimpses), (0.012201713657423653, intimate)]\n"
     ]
    }
   ],
   "source": [
    "# Running TextRank\n",
    "nx_words = nx.from_numpy_matrix(adjacency.as_matrix())\n",
    "ranks=nx.pagerank(nx_words, alpha=.85, tol=.00000001)\n",
    "\n",
    "# Identifying the five most highly ranked keywords\n",
    "ranked = sorted(((ranks[i],s) for i,s in enumerate(words)),\n",
    "                reverse=True)\n",
    "print(ranked[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill\n",
    "It is also possible that keyword phrases will work better. Modifiy the keyword extraction code to extract two-word phrases (digrams) rather than single words. Then try it with trigrams. You will probably want to broaden the window that defines 'neighbors.' Try a few different modifications, and write up your observations in your notebook. Discuss with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mcgow\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "def get_bigrams(myString):\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    tokens = tokenizer.tokenize(myString)\n",
    "    stemmer = PorterStemmer()\n",
    "    bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "    bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 500)\n",
    "\n",
    "    for bigram_tuple in bigrams:\n",
    "        x = \"%s %s\" % bigram_tuple\n",
    "        tokens.append(x)\n",
    "\n",
    "    result = [' '.join([stemmer.stem(w).lower() for w in x.split()]) for x in tokens if x.lower() not in stopwords.words('english') and len(x) > 8]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In my younger and more vulnerable years my father gave me some advice that I've been turning over in my mind ever since. \"Whenever you feel like criticizing any one,\" he told me, \"just remember that all the people in this world haven't had the advantages that you've had.\" He didn't say any more but we've always been unusually communicative in a reserved way, and I understood that he meant a great deal more than that. In consequence I'm inclined to reserve all judgments, a habit that has opened up many curious natures to me and also made me the victim of not a few veteran bores. The abnormal mind is quick to detect and attach itself to this quality when it appears in a normal person, and so it came about that in college I was unjustly accused of being a politician, because I was privy to the secret griefs of wild, unknown men. Most of the confidences were unsought--frequently I have feigned sleep, preoccupation, or a hostile levity when I realized by some unmistakable sign that an intimate revelation was quivering on the horizon--for the intimate revelations of young men or at least the terms in which they express them are usually plagiaristic and marred by obvious suppressions. Reserving judgments is a matter of infinite hope. I am still a little afraid of missing something if I forget that, as my father snobbishly suggested, and I snobbishly repeat a sense of the fundamental decencies is parcelled out unequally at birth. And, after boasting this way of my tolerance, I come to the admission that it has a limit. Conduct may be founded on the hard rock or the wet marshes but after a certain point I don't care what it's founded on. When I came back from the East last autumn I felt that I wanted the world to be in uniform and at a sort of moral attention forever; I wanted no more riotous excursions with privileged glimpses into the human heart. Only Gatsby, the man who gives his name to this book, was exempt from my reaction--Gatsby who represented everything for which I have an unaffected scorn. If personality is an unbroken series of successful gestures, then there was something gorgeous about him, some heightened sensitivity to the promises of life, as if he were related to one of those intricate machines that register earthquakes ten thousand miles away. This responsiveness had nothing to do with that flabby impressionability which is dignified under the name of the \"creative temperament\"--it was an extraordinary gift for hope, a romantic readiness such as I have never found in any other person and which it is not likely I shall ever find again. No--Gatsby turned out all right at the end; it is what preyed on Gatsby, what foul dust floated in the wake of his dreams that temporarily closed out my interest in the abortive sorrows and short-winded elations of men."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gatsby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In,\n",
       " my,\n",
       " and,\n",
       " more,\n",
       " my,\n",
       " me,\n",
       " some,\n",
       " that,\n",
       " I,\n",
       " 've,\n",
       " been,\n",
       " over,\n",
       " in,\n",
       " my,\n",
       " ever,\n",
       " since,\n",
       " Whenever,\n",
       " you,\n",
       " any,\n",
       " one,\n",
       " he,\n",
       " me,\n",
       " just,\n",
       " that,\n",
       " all,\n",
       " the,\n",
       " in,\n",
       " this,\n",
       " have,\n",
       " n't,\n",
       " had,\n",
       " the,\n",
       " that,\n",
       " you,\n",
       " 've,\n",
       " had,\n",
       " He,\n",
       " did,\n",
       " n't,\n",
       " say,\n",
       " any,\n",
       " more,\n",
       " but,\n",
       " we,\n",
       " 've,\n",
       " always,\n",
       " been,\n",
       " in,\n",
       " a,\n",
       " and,\n",
       " I,\n",
       " that,\n",
       " he,\n",
       " a,\n",
       " more,\n",
       " than,\n",
       " that,\n",
       " In,\n",
       " I,\n",
       " 'm,\n",
       " to,\n",
       " all,\n",
       " a,\n",
       " that,\n",
       " has,\n",
       " up,\n",
       " many,\n",
       " to,\n",
       " me,\n",
       " and,\n",
       " also,\n",
       " made,\n",
       " me,\n",
       " the,\n",
       " of,\n",
       " not,\n",
       " a,\n",
       " few,\n",
       " The,\n",
       " is,\n",
       " to,\n",
       " and,\n",
       " itself,\n",
       " to,\n",
       " this,\n",
       " when,\n",
       " it,\n",
       " in,\n",
       " a,\n",
       " and,\n",
       " so,\n",
       " it,\n",
       " about,\n",
       " that,\n",
       " in,\n",
       " I,\n",
       " was,\n",
       " of,\n",
       " being,\n",
       " a,\n",
       " because,\n",
       " I,\n",
       " was,\n",
       " to,\n",
       " the,\n",
       " of,\n",
       " Most,\n",
       " of,\n",
       " the,\n",
       " were,\n",
       " I,\n",
       " have,\n",
       " or,\n",
       " a,\n",
       " when,\n",
       " I,\n",
       " by,\n",
       " some,\n",
       " that,\n",
       " an,\n",
       " was,\n",
       " on,\n",
       " the,\n",
       " for,\n",
       " the,\n",
       " of,\n",
       " or,\n",
       " at,\n",
       " least,\n",
       " the,\n",
       " in,\n",
       " which,\n",
       " they,\n",
       " them,\n",
       " are,\n",
       " and,\n",
       " by,\n",
       " is,\n",
       " a,\n",
       " of,\n",
       " I,\n",
       " am,\n",
       " still,\n",
       " a,\n",
       " of,\n",
       " something,\n",
       " if,\n",
       " I,\n",
       " that,\n",
       " as,\n",
       " my,\n",
       " and,\n",
       " I,\n",
       " a,\n",
       " of,\n",
       " the,\n",
       " is,\n",
       " out,\n",
       " at,\n",
       " And,\n",
       " after,\n",
       " this,\n",
       " of,\n",
       " my,\n",
       " I,\n",
       " to,\n",
       " the,\n",
       " that,\n",
       " it,\n",
       " has,\n",
       " a,\n",
       " may,\n",
       " be,\n",
       " on,\n",
       " the,\n",
       " or,\n",
       " the,\n",
       " but,\n",
       " after,\n",
       " a,\n",
       " I,\n",
       " do,\n",
       " n't,\n",
       " what,\n",
       " it,\n",
       " 's,\n",
       " on,\n",
       " When,\n",
       " I,\n",
       " back,\n",
       " from,\n",
       " the,\n",
       " last,\n",
       " I,\n",
       " that,\n",
       " I,\n",
       " the,\n",
       " to,\n",
       " be,\n",
       " in,\n",
       " and,\n",
       " at,\n",
       " a,\n",
       " of,\n",
       " I,\n",
       " no,\n",
       " more,\n",
       " with,\n",
       " into,\n",
       " the,\n",
       " Only,\n",
       " the,\n",
       " who,\n",
       " his,\n",
       " name,\n",
       " to,\n",
       " this,\n",
       " was,\n",
       " from,\n",
       " my,\n",
       " who,\n",
       " everything,\n",
       " for,\n",
       " which,\n",
       " I,\n",
       " have,\n",
       " an,\n",
       " If,\n",
       " is,\n",
       " an,\n",
       " of,\n",
       " then,\n",
       " there,\n",
       " was,\n",
       " something,\n",
       " about,\n",
       " him,\n",
       " some,\n",
       " to,\n",
       " the,\n",
       " of,\n",
       " as,\n",
       " if,\n",
       " he,\n",
       " were,\n",
       " to,\n",
       " one,\n",
       " of,\n",
       " those,\n",
       " that,\n",
       " ten,\n",
       " This,\n",
       " had,\n",
       " nothing,\n",
       " to,\n",
       " do,\n",
       " with,\n",
       " that,\n",
       " which,\n",
       " is,\n",
       " under,\n",
       " the,\n",
       " name,\n",
       " of,\n",
       " the,\n",
       " was,\n",
       " an,\n",
       " for,\n",
       " a,\n",
       " such,\n",
       " as,\n",
       " I,\n",
       " have,\n",
       " never,\n",
       " in,\n",
       " any,\n",
       " other,\n",
       " and,\n",
       " which,\n",
       " it,\n",
       " is,\n",
       " not,\n",
       " I,\n",
       " ever,\n",
       " again,\n",
       " No,\n",
       " out,\n",
       " all,\n",
       " at,\n",
       " the,\n",
       " it,\n",
       " is,\n",
       " what,\n",
       " on,\n",
       " what,\n",
       " in,\n",
       " the,\n",
       " of,\n",
       " his,\n",
       " that,\n",
       " out,\n",
       " my,\n",
       " in,\n",
       " the,\n",
       " and,\n",
       " of]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in gatsby if word.is_stop==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[years my,\n",
       " meant a,\n",
       " . In,\n",
       " reserve all,\n",
       " , a,\n",
       " . The,\n",
       " mind is,\n",
       " griefs of,\n",
       " wild,,\n",
       " , unknown,\n",
       " confidences were,\n",
       " sleep,,\n",
       " revelations of,\n",
       " marred by,\n",
       " . Reserving,\n",
       " matter of,\n",
       " repeat a,\n",
       " unequally at,\n",
       " boasting this,\n",
       " limit.,\n",
       " East last,\n",
       " wanted the,\n",
       " sort of,\n",
       " excursions with,\n",
       " , the,\n",
       " , was,\n",
       " . If,\n",
       " series of,\n",
       " promises of,\n",
       " . This,\n",
       " gift for,\n",
       " , a,\n",
       " , what,\n",
       " short-,\n",
       " -winded,\n",
       " elations of]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "gatsby_filt = [gatsby[i-2:i] for i, word in enumerate(gatsby) if word.is_stop==False and (word.pos_=='NOUN' or word.pos_=='ADJ')]\n",
    "gatsby_filt = [group for group in gatsby_filt if (group[0].is_stop==False) ]\n",
    "gatsby_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got spacy.tokens.span.Span)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-2c07bbe84094>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Checking if any of the word's next four neighbors are in the word list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgatsby_filt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Making sure to stop at the end of the string, even if there are less than four words left after the target.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-2c07bbe84094>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# Checking if any of the word's next four neighbors are in the word list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgatsby_filt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Making sure to stop at the end of the string, even if there are less than four words left after the target.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgatsby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'other' has incorrect type (expected spacy.tokens.token.Token, got spacy.tokens.span.Span)"
     ]
    }
   ],
   "source": [
    "# Removing stop words and punctuation, then getting a list of all bigrams in the text\n",
    "gatsby_filt = [gatsby[i-2:i] for i, word in enumerate(gatsby) if word.is_stop==False and (word.pos_=='NOUN' or word.pos_=='ADJ')]\n",
    "gatsby_filt = [group for group in gatsby_filt if (group[0].is_stop==False) ]\n",
    "words=set(gatsby_filt)\n",
    "\n",
    "#Creating a grid indicating whether words are within 4 places of the target word\n",
    "adjacency=pd.DataFrame(columns=words,index=words,data=0)\n",
    "\n",
    "#Iterating through each word in the text and indicating which of the unique words are its neighbors\n",
    "for i,word in enumerate(gatsby):\n",
    "    # Checking if any of the word's next four neighbors are in the word list \n",
    "    if any([word == item for item in gatsby_filt]):\n",
    "        # Making sure to stop at the end of the string, even if there are less than four words left after the target.\n",
    "        end=max(0,len(gatsby)-(len(gatsby)-(i+5)))\n",
    "        # The potential neighbors.\n",
    "        nextwords=gatsby[i+1:end]\n",
    "        # Filtering the neighbors to select only those in the word list\n",
    "        inset=[x in gatsby_filt for x in nextwords]\n",
    "        neighbors=[nextwords[i] for i in range(len(nextwords)) if inset[i]]\n",
    "        # Adding 1 to the adjacency matrix for neighbors of the target word\n",
    "        if neighbors:\n",
    "            adjacency.loc[word,neighbors]=adjacency.loc[word,neighbors]+1\n",
    "\n",
    "print('done!')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
